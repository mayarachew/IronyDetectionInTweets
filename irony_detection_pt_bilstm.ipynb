{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "irony_detection_pt_bilstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFtL+DbY1WoPp1XyXl2HsP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayarachew/IronyDetectionInTweets/blob/main/irony_detection_pt_bilstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bhJZdJaSk0mu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e0650e-1893-45a4-9455-a57ee97d5d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/My Drive/sentiment_analysis/irony_detection_EN_taskA\" \"irony_detection_EN\"\n",
        "!cp -r \"/content/drive/My Drive/sentiment_analysis/irony_detection_pt2\" \"irony_detection_pt2\""
      ],
      "metadata": {
        "id": "0H4Q8s1CmGCW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text"
      ],
      "metadata": {
        "id": "9-mA1ZKFmpUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "722e9917-a7b7-4bdc-e4e7-9157c69b7501"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 19.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (13.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.21.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.43.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.13.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.24.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.5.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 53.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-text\n",
            "Successfully installed tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation,Dropout, Flatten, Embedding, SimpleRNN\n",
        "from keras.datasets import reuters\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing import sequence\n",
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "d_kI-a9tsUFc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_train = \"irony_detection_pt2/ironico-train.txt\"\n",
        "path_valid = \"irony_detection_pt2/ironico-valid.txt\"\n",
        "path_test = \"irony_detection_pt2/ironico-test.txt\""
      ],
      "metadata": {
        "id": "LQlVP9RXmWKN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(path_train, sep='\\t',encoding=\"UTF-8\",low_memory = False)\n",
        "df_valid = pd.read_csv(path_valid, sep='\\t',encoding=\"UTF-8\",low_memory = False)\n",
        "df_test = pd.read_csv(path_test, sep='\\t',encoding=\"UTF-8\",low_memory = False)\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "W_CkgJDqrxrF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "31e13437-ae33-4619-e87f-1cad55164d67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-89386f70-aff2-4126-a0e9-3fde661004b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.728316e+17</td>\n",
              "      <td>Jogo será em Manaus, muito mais longe que a Co...</td>\n",
              "      <td>ironico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.658627e+17</td>\n",
              "      <td>Diferença de renda entre brancos enegros cresc...</td>\n",
              "      <td>nao-ironico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.699588e+17</td>\n",
              "      <td>ECONOMIA CRISE RECESSÃO FORATEMER DIRETASJÁ: C...</td>\n",
              "      <td>nao-ironico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.378169e+17</td>\n",
              "      <td>Instagram, aquele programa de tirar foto da co...</td>\n",
              "      <td>ironico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.330307e+17</td>\n",
              "      <td>• MARQUEM OS AMIGOS •bomdia boatarde boanoite ...</td>\n",
              "      <td>ironico</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89386f70-aff2-4126-a0e9-3fde661004b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89386f70-aff2-4126-a0e9-3fde661004b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89386f70-aff2-4126-a0e9-3fde661004b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             id                                               text        Label\n",
              "0  7.728316e+17  Jogo será em Manaus, muito mais longe que a Co...      ironico\n",
              "1  8.658627e+17  Diferença de renda entre brancos enegros cresc...  nao-ironico\n",
              "2  8.699588e+17  ECONOMIA CRISE RECESSÃO FORATEMER DIRETASJÁ: C...  nao-ironico\n",
              "3  5.378169e+17  Instagram, aquele programa de tirar foto da co...      ironico\n",
              "4  7.330307e+17  • MARQUEM OS AMIGOS •bomdia boatarde boanoite ...      ironico"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['Label'] = pd.Categorical(df_test['Label'])\n",
        "df_test['Label'] = df_test['Label'].cat.codes\n",
        "\n",
        "df_train['Label'] = pd.Categorical(df_train['Label'])\n",
        "df_train['Label'] = df_train['Label'].cat.codes\n",
        "\n",
        "df_valid['Label'] = pd.Categorical(df_valid['Label'])\n",
        "df_valid['Label'] = df_valid['Label'].cat.codes"
      ],
      "metadata": {
        "id": "NhetYpklsyB7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = df_train['Label']\n",
        "X_train = df_train['text']\n",
        "\n",
        "y_test = df_test['Label']\n",
        "X_test = df_test['text']\n",
        "\n",
        "y_valid = df_valid['Label']\n",
        "X_valid = df_valid['text']"
      ],
      "metadata": {
        "id": "GtoXk9BoryXV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.dtypes\n"
      ],
      "metadata": {
        "id": "V4Xx__cczY9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2099ab-a1e2-4c3b-e46f-ed32dbba2081"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id       float64\n",
              "text      object\n",
              "Label       int8\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "\n",
        "\n",
        "results = Counter()\n",
        "df_train['text'].str.lower().str.split().apply(results.update)\n",
        "df_valid['text'].str.lower().str.split().apply(results.update)\n",
        "df_test['text'].str.lower().str.split().apply(results.update)\n",
        "total_vocab_size = len(results)"
      ],
      "metadata": {
        "id": "MfLRKtQ3mKpm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soma = 0\n",
        "\n",
        "for item in df_train['text']:\n",
        "  soma += len(item)\n",
        "media = soma/len(df_train['text'])\n",
        "print(f'Em média, cada tweets possui {media} palavras.')"
      ],
      "metadata": {
        "id": "qwoESY8g21bp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594d83b2-fe03-4df9-bd7e-27e22598ae7c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Em média, cada tweets possui 72.57977736549165 palavras.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hiperparametros"
      ],
      "metadata": {
        "id": "uo36NUe33AV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 1000 # make the top list of words (common words)\n",
        "embedding_dim = 32\n",
        "max_length = 32\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = '<OOV>' # OOV = Out of Vocabulary"
      ],
      "metadata": {
        "id": "5A5jAt6ml-nm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "M_N8MfIT3G3P"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "len(word_index)"
      ],
      "metadata": {
        "id": "HQG4IDik3N8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc206ae5-5671-4651-9a64-61cc092c3a10"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21223"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "valid_sequences = tokenizer.texts_to_sequences(X_valid)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "X_valid_padded = pad_sequences(valid_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "X_test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n"
      ],
      "metadata": {
        "id": "Ja6uDT6euApv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando se está tudo correto"
      ],
      "metadata": {
        "id": "L0PuxAqI3yKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.iloc[3])\n",
        "print(X_train_padded[3])"
      ],
      "metadata": {
        "id": "V_7u7j9SuDLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68a86fd-3238-4512-ac57-340dd96670c7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instagram, aquele programa de tirar foto da comida, sqn!  tirando onda zuacao … \n",
            "[782 350 473   2 426 294  11 933 147   1   1   1 175   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_padded.shape, X_valid_padded.shape"
      ],
      "metadata": {
        "id": "96L6KXnG7lFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e47aff9-38a0-400a-afaf-524e67180193"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10780, 32), (2310, 32))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_valid = to_categorical(y_valid)\n",
        "#y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "GAT6NTdpuRDm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segue o modelo LSTM"
      ],
      "metadata": {
        "id": "PUMbZxfTtROx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM,Bidirectional\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, output_dim=max_length, input_length=max_length))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('sigmoid'))\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "S0oQObrHtQYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09320a46-22bc-4d33-c9e9-b7312de03487"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 32, 32)            32000     \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 32, 128)          49664     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 128)           0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 64)               41216     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 130       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 2)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 123,010\n",
            "Trainable params: 123,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "#sgd = SGD(learning_rate=0.05)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "opt = Adam(learning_rate=0.01, decay=1e-6)\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "#model.compile(optimizer='adam',\n",
        "#                   loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "#                   metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OL9ZvwaiudTF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_padded,y_train,validation_data=(X_valid_padded,y_valid),epochs=20)"
      ],
      "metadata": {
        "id": "YaFB_4xfugKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "287945c6-8bea-4d24-bced-93663d2e6c9f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "337/337 [==============================] - 32s 72ms/step - loss: 0.1017 - accuracy: 0.9687 - val_loss: 0.0223 - val_accuracy: 0.9961\n",
            "Epoch 2/20\n",
            "337/337 [==============================] - 22s 64ms/step - loss: 0.0347 - accuracy: 0.9929 - val_loss: 0.0232 - val_accuracy: 0.9948\n",
            "Epoch 3/20\n",
            "337/337 [==============================] - 22s 66ms/step - loss: 0.0412 - accuracy: 0.9917 - val_loss: 0.0271 - val_accuracy: 0.9957\n",
            "Epoch 4/20\n",
            "337/337 [==============================] - 22s 65ms/step - loss: 0.0382 - accuracy: 0.9917 - val_loss: 0.0207 - val_accuracy: 0.9952\n",
            "Epoch 5/20\n",
            "337/337 [==============================] - 22s 65ms/step - loss: 0.0261 - accuracy: 0.9944 - val_loss: 0.0471 - val_accuracy: 0.9861\n",
            "Epoch 6/20\n",
            "337/337 [==============================] - 22s 65ms/step - loss: 0.0308 - accuracy: 0.9937 - val_loss: 0.0282 - val_accuracy: 0.9939\n",
            "Epoch 7/20\n",
            "337/337 [==============================] - 22s 65ms/step - loss: 0.0254 - accuracy: 0.9944 - val_loss: 0.0296 - val_accuracy: 0.9935\n",
            "Epoch 8/20\n",
            "337/337 [==============================] - 23s 67ms/step - loss: 0.0230 - accuracy: 0.9950 - val_loss: 0.0275 - val_accuracy: 0.9935\n",
            "Epoch 9/20\n",
            "337/337 [==============================] - 22s 65ms/step - loss: 0.0217 - accuracy: 0.9949 - val_loss: 0.0370 - val_accuracy: 0.9900\n",
            "Epoch 10/20\n",
            "337/337 [==============================] - 22s 65ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.0238 - val_accuracy: 0.9952\n",
            "Epoch 11/20\n",
            "337/337 [==============================] - 23s 67ms/step - loss: 0.0193 - accuracy: 0.9954 - val_loss: 0.0312 - val_accuracy: 0.9948\n",
            "Epoch 12/20\n",
            "337/337 [==============================] - 22s 65ms/step - loss: 0.0197 - accuracy: 0.9955 - val_loss: 0.1456 - val_accuracy: 0.9550\n",
            "Epoch 13/20\n",
            "337/337 [==============================] - 22s 65ms/step - loss: 0.0208 - accuracy: 0.9955 - val_loss: 0.0333 - val_accuracy: 0.9913\n",
            "Epoch 14/20\n",
            "337/337 [==============================] - 22s 65ms/step - loss: 0.0175 - accuracy: 0.9961 - val_loss: 0.0330 - val_accuracy: 0.9931\n",
            "Epoch 15/20\n",
            "337/337 [==============================] - 22s 66ms/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.0370 - val_accuracy: 0.9931\n",
            "Epoch 16/20\n",
            "337/337 [==============================] - 22s 66ms/step - loss: 0.0188 - accuracy: 0.9955 - val_loss: 0.0409 - val_accuracy: 0.9913\n",
            "Epoch 17/20\n",
            "337/337 [==============================] - 22s 66ms/step - loss: 0.0147 - accuracy: 0.9972 - val_loss: 0.0340 - val_accuracy: 0.9918\n",
            "Epoch 18/20\n",
            "337/337 [==============================] - 22s 65ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.0346 - val_accuracy: 0.9909\n",
            "Epoch 19/20\n",
            "337/337 [==============================] - 22s 65ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0353 - val_accuracy: 0.9935\n",
            "Epoch 20/20\n",
            "337/337 [==============================] - 22s 66ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.0367 - val_accuracy: 0.9935\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbcd48fdf10>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "    plt.plot(history.history[metric])\n",
        "    plt.plot(history.history['val_'+metric], '')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([metric, 'val_'+metric])\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plot_graphs(history, 'accuracy')\n",
        "    plt.ylim(None, 1)\n",
        "    #plt.xticks(range(0,20))\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plot_graphs(history, 'loss')\n",
        "    plt.ylim(0, None)\n",
        "    #plt.xticks(range(0,20))"
      ],
      "metadata": {
        "id": "sepT496a5MXH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "_, test_acc = model.evaluate(X_test_padded, to_categorical(y_test), verbose=0)\n",
        "print(test_acc)\n",
        "\n",
        "y_pred = model.predict(X_test_padded, batch_size=50, verbose=2)\n",
        "\n",
        "# get the class with highest probability for each sample\n",
        "y_pred = np.argmax(y_pred, axis=-1)\n",
        "\n",
        "# get the classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "p1aVfStSvph6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5db3748-5cec-4f1e-9a42-646b8ca3de8d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9926406741142273\n",
            "47/47 - 2s - 2s/epoch - 50ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1902\n",
            "           1       0.98      0.98      0.98       408\n",
            "\n",
            "    accuracy                           0.99      2310\n",
            "   macro avg       0.99      0.99      0.99      2310\n",
            "weighted avg       0.99      0.99      0.99      2310\n",
            "\n"
          ]
        }
      ]
    }
  ]
}